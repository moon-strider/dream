name: llm-based-response-selector
endpoints:
- respond
compose:
  env_file: [ .env,.env_secret ]
  build:
    args:
      SERVICE_PORT: 8003
      SERVICE_NAME: response_selector
      LANGUAGE: EN
      GENERATIVE_SERVICE_URL: http://openai-api-chatgpt:8145/respond
      GENERATIVE_SERVICE_CONFIG: openai-chatgpt-long.json
      GENERATIVE_TIMEOUT: 120
      N_UTTERANCES_CONTEXT: 1
      FILTER_TOXIC_OR_BADLISTED: 0
      PROMPT_FILE: common/prompts/response_selector.json
      FLASK_APP: server
    context: .
    dockerfile: ./response_selectors/llm_based_response_selector/Dockerfile
  command: flask run -h 0.0.0.0 -p 8003
  environment:
    - FLASK_APP=server
  deploy:
    resources:
      limits:
        memory: 100M
      reservations:
        memory: 100M
  ports:
  - 8003:8003
proxy: null
