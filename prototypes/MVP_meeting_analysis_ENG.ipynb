{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5Hvg_NDd1Wq"
      },
      "source": [
        "Teams presents files in two formats: docx and vtt.\n",
        "\n",
        "- **docx** files include profile pics & names, time (from start, mm:ss), utterances and meta information (X joined, Y left, recording started, etc.)\n",
        "\n",
        "- **vtt** (subtitle format) files include time (from start, HH:mm:ss.SSS) and utterances.\n",
        "\n",
        "As of now, I work with docx files only as we need the speakers' names."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdoxtcRz6k5h"
      },
      "source": [
        "## Prepartion: installing packages & creating functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAn5hs3V9dXA"
      },
      "source": [
        "Uncomment this cell for better view in google colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from IPython.display import HTML, display\n",
        "\n",
        "# def set_css():\n",
        "#   display(HTML('''\n",
        "#   <style>\n",
        "#     pre {\n",
        "#         white-space: pre-wrap;\n",
        "#     }\n",
        "#   </style>\n",
        "#   '''))\n",
        "# get_ipython().events.register('pre_run_cell', set_css)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mDEPRECATION: simplify-docx 0.1.2 has a non-standard dependency specifier six>=1.12.0<2. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of simplify-docx or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip install -q openai docx simplify_docx tiktoken gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import docx\n",
        "import re\n",
        "import openai\n",
        "import tiktoken\n",
        "import gdown\n",
        "import json\n",
        "from tqdm.notebook import tqdm\n",
        "from simplify_docx import simplify\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "bD-uoQkjhaX9",
        "outputId": "48bc6934-81f0-4a44-d878-dae977013e11"
      },
      "outputs": [],
      "source": [
        "def get_text(json_part):\n",
        "    str_to_return = json_part[\"VALUE\"][-1][\"VALUE\"]\n",
        "    return str_to_return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "MKqtdu2ZkbYj",
        "outputId": "c5a8335f-8b07-4dfe-9562-5bd15039f488"
      },
      "outputs": [],
      "source": [
        "def structure_data_old(meeting_transcipt):\n",
        "    meeting_transcipt_dict = {\"datetime\": '', \"people_present\": [], \"utterances\": []}\n",
        "    for n, item in enumerate(meeting_transcipt):\n",
        "        if n == 1:\n",
        "            meeting_transcipt_dict[\"datetime\"] = item\n",
        "        elif \"joined the meeting\" in item:\n",
        "            person = item.replace(\" joined the meeting\", \"\").strip()\n",
        "            meeting_transcipt_dict[\"people_present\"].append(person)\n",
        "        elif \"   \" in item:\n",
        "             item = [x for x in re.split(r'   |\\r', item) if x]\n",
        "             person = item[0]\n",
        "             time = item[1]\n",
        "             utts = ' '.join(item[2:])\n",
        "             one_utt = {\"time_start\": time, \"person\": person, \"sentences\": utts}\n",
        "             meeting_transcipt_dict[\"utterances\"].append(one_utt)\n",
        "    return meeting_transcipt_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def structure_data(meeting_transcipt):\n",
        "    meeting_transcipt_dict = {\"datetime\": '', \"people_present\": [], \"utterances\": []}\n",
        "    people = []\n",
        "    for n, item in enumerate(meeting_transcipt):\n",
        "        if \"   \" in item or \"\\r\" in item:\n",
        "             item = [x for x in re.split(r'   |\\r', item) if x]\n",
        "             time = item[0]\n",
        "             person = item[1]\n",
        "             utts = ' '.join(item[2:])\n",
        "             one_utt = {\"time_start\": time, \"person\": person, \"sentences\": utts}\n",
        "             meeting_transcipt_dict[\"utterances\"].append(one_utt)\n",
        "             if person not in people:\n",
        "                people.append(person)\n",
        "    meeting_transcipt_dict[\"people_present\"] = people\n",
        "    return meeting_transcipt_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def concat_utterances(transcript):\n",
        "    speaker = transcript[0][\"person\"]\n",
        "    concat_utt = transcript[0][\"sentences\"]\n",
        "    transcript_concat = []\n",
        "    for utt in transcript[1:]:\n",
        "        if speaker == utt[\"person\"]:\n",
        "            concat_utt += f' {utt[\"sentences\"]}'\n",
        "        else:\n",
        "            transcript_concat.append({'person': speaker, 'sentences': concat_utt})\n",
        "            concat_utt = utt[\"sentences\"]\n",
        "            speaker = utt[\"person\"]\n",
        "    return transcript_concat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_transcript(dict_data):\n",
        "    if \"utterances\" in dict_data:\n",
        "        utterances = dict_data[\"utterances\"]\n",
        "    else:\n",
        "        utterances = dict_data\n",
        "    transcript_concat = concat_utterances(utterances)\n",
        "    transcript_list = [f'{utt[\"person\"]}: {utt[\"sentences\"]}' for utt in transcript_concat]\n",
        "    return transcript_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_token_number(text):\n",
        "    enc = tiktoken.encoding_for_model(\"gpt-4\")\n",
        "    return len(enc.encode(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def decide_where_to_break(transcript_list, limit=3000):\n",
        "    len_tokens = 0\n",
        "    break_points = []\n",
        "    for n, utt in enumerate(transcript_list):\n",
        "        len_tokens += check_token_number(utt)\n",
        "        if len_tokens > limit:\n",
        "            len_tokens = check_token_number(utt)\n",
        "            break_points.append(n-1)\n",
        "    return break_points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_transcript_into_chunks(transcript, break_points):\n",
        "    transcript_chunks = []\n",
        "    start_point = 0\n",
        "    for break_point in break_points:\n",
        "        chunk = transcript[start_point:break_point]\n",
        "        transcript_chunks.append(chunk)\n",
        "        start_point = break_point\n",
        "    transcript_chunks.append(transcript[start_point:])\n",
        "    return transcript_chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPA3P6WExoi-"
      },
      "source": [
        "NB: gpt-4 also has a larger context window with a maximum size of **8,192** tokens compared to **4,096** tokens for gpt-3.5-turbo. However, gpt-3.5-turbo returns outputs with lower latency and costs much less per token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "default_system_message = \"You are an office worker helper. You summarize transcripts, create key points, and write lists of tasks.\"\n",
        "default_prompt = \"\"\"Meeting transcript:\n",
        "{chunk_text}\n",
        "Provide the summary of the meeting based on the meeting transcript.\"\"\"\n",
        "\n",
        "\n",
        "def send_prompt_to_openai(prompt=default_prompt, system_message=default_system_message, openai_model=\"gpt-4\"):\n",
        "    response = openai.ChatCompletion.create(\n",
        "    model=openai_model,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt},\n",
        "    ]\n",
        "    )\n",
        "    response_text = response[\"choices\"][-1][\"message\"][\"content\"]\n",
        "    return response_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_meeting_chunks_update(transcript_chunks, prompt_first, prompt_others):\n",
        "    all_responses = []\n",
        "    for n, chunk in tqdm(enumerate(transcript_chunks)):\n",
        "        chunk_text = '\\n'.join(chunk)\n",
        "        if n == 0:\n",
        "            prompt = prompt_first.replace('{chunk_text}', chunk_text)\n",
        "        else:\n",
        "            prompt = prompt_others.replace('{response}', response).replace('{chunk_text}', chunk_text)\n",
        "        response = send_prompt_to_openai(prompt=prompt)\n",
        "        print(f'tokens in response: {check_token_number(response)}')\n",
        "        all_responses.append(response)\n",
        "    return all_responses\n",
        "\n",
        "\n",
        "def process_meeting_chunks_concat(transcript_chunks, prompt_first, prompt_final, openai_model='gpt-4'):\n",
        "    all_responses = []\n",
        "    for n, chunk in enumerate(tqdm(transcript_chunks)):\n",
        "        chunk_text = '\\n'.join(chunk)\n",
        "        prompt = prompt_first.replace('{chunk_text}', chunk_text)\n",
        "        response = send_prompt_to_openai(prompt=prompt, openai_model=openai_model)\n",
        "        print(f'tokens in response: {check_token_number(response)}')\n",
        "        all_responses.append(response)\n",
        "    print(f'Processing responses to get the final answer. This should take around 45 seconds.')\n",
        "    gpt_responses = '\\n'.join(all_responses)\n",
        "    prompt_final = prompt_final.replace(\"{gpt_responses}\", gpt_responses)\n",
        "    final_response = send_prompt_to_openai(prompt=prompt_final, openai_model='gpt-4')\n",
        "    all_responses.append(final_response)\n",
        "    return all_responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_meeting_teams(filepath, prompt_first, prompt_final, openai_model='gpt-4'):\n",
        "    my_doc = docx.Document(filepath)\n",
        "    my_doc_as_json = simplify(my_doc)\n",
        "    list_data = [get_text(json_part) for json_part in my_doc_as_json['VALUE'][0]['VALUE']]\n",
        "    dict_data = structure_data(list_data)\n",
        "    transcript = make_transcript(dict_data)\n",
        "    if openai_model == 'gpt-4':\n",
        "        token_limit = 6500\n",
        "    else:\n",
        "        token_limit = 3000\n",
        "    break_points = decide_where_to_break(transcript, limit=token_limit)\n",
        "    transcript_chunks = split_transcript_into_chunks(transcript, break_points)\n",
        "    result = process_meeting_chunks_concat(transcript_chunks, prompt_first, prompt_final, openai_model=openai_model)\n",
        "    return result\n",
        "\n",
        "\n",
        "def process_meeting_teams_old(filepath, prompt_first, prompt_final, openai_model='gpt-4'):\n",
        "    my_doc = docx.Document(filepath)\n",
        "    my_doc_as_json = simplify(my_doc)\n",
        "    list_data = [get_text(json_part) for json_part in my_doc_as_json['VALUE'][0]['VALUE']]\n",
        "    dict_data = structure_data_old(list_data)\n",
        "    transcript = make_transcript(dict_data)\n",
        "    if openai_model == 'gpt-4':\n",
        "        token_limit = 6500\n",
        "    else:\n",
        "        token_limit = 3000\n",
        "    break_points = decide_where_to_break(transcript, limit=token_limit)\n",
        "    transcript_chunks = split_transcript_into_chunks(transcript, break_points)\n",
        "    result = process_meeting_chunks_concat(transcript_chunks, prompt_first, prompt_final, openai_model=openai_model)\n",
        "    return result\n",
        "\n",
        "\n",
        "def process_meeting_ami_corpus(filepath,  prompt_first, prompt_final, openai_model='gpt-4'):\n",
        "    with open(filepath, 'r') as file:\n",
        "        data = json.load(file)\n",
        "    meeting_chunks_dict = {}\n",
        "    for meeting_name, meeting_content in data.items():\n",
        "        transcript = make_transcript(meeting_content)\n",
        "        if openai_model == 'gpt-4':\n",
        "            token_limit = 6500\n",
        "        else:\n",
        "            token_limit = 3000\n",
        "        break_points = decide_where_to_break(transcript, limit=token_limit)\n",
        "        transcript_chunks = split_transcript_into_chunks(transcript, break_points)\n",
        "        meeting_chunks_dict[meeting_name] = transcript_chunks\n",
        "    meeting_results = {}\n",
        "    for meeting_name, transcript_chunks in meeting_chunks_dict.items():\n",
        "        result = process_meeting_chunks_concat(transcript_chunks, prompt_first, prompt_final, openai_model=openai_model)\n",
        "        meeting_results[meeting_name] = result\n",
        "    return meeting_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBazb75U6s2w"
      },
      "source": [
        "## Prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt_first_summary = \"\"\"Meeting transcript:\n",
        "{chunk_text}\n",
        "Provide a full summary of the meeting based on the meeting transcript.\n",
        "Be concise but mention all important details. Do not include tasks separately.\"\"\"\n",
        "\n",
        "prompt_others_summary = \"\"\"New information:\n",
        "{chunk_text}\n",
        "Previous summary:\n",
        "{response}\n",
        "Extend the previous summary based on New information.\n",
        "Provide the updated summary as a whole, preserving all information from Previous summary.\"\"\"\n",
        "\n",
        "prompt_final_summary = \"\"\"Here is are parts of a summary of a work meeting:\n",
        "{gpt_responses}\n",
        "Combine them to provide a complete and coherent summary.\n",
        "It must include all the information from the parts above.\n",
        "You should abridge the text and leave out minor detailes when possible.\"\"\"\n",
        "\n",
        "prompt_first_future_tasks = \"\"\"Meeting transcript:\n",
        "{chunk_text}\n",
        "Write the lists of future to-do tasks set for each speaker.\n",
        "Only mention new tasks that were set during this call and will be started later.\n",
        "Do not mention tasks that are in progress.\n",
        "Give one list of future tasks for each speaker without extra information.\"\"\"\n",
        "\n",
        "prompt_others_future_tasks = \"\"\"Previous lists of future tasks:\n",
        "{response}\n",
        "Amend the lists of future tasks based on this part of the transcript:\n",
        "{chunk_text}\n",
        "Only mention tasks that were set during this call.\n",
        "Provide the lists of future tasks as a whole, preserving all information from Previous lists of future tasks.\n",
        "Give one list of future tasks for each speaker without extra information.\"\"\"\n",
        "\n",
        "prompt_final_future_tasks = \"\"\"Here is a list of future to-do tasks set for each speaker:\n",
        "{gpt_responses}\n",
        "Format the list to use correct numbering and get rid of duplicate items.\"\"\"\n",
        "\n",
        "prompt_first_completed_tasks = \"\"\"Meeting transcript:\n",
        "{chunk_text}\n",
        "Write the lists of tasks that each speaker completed before the meeting. Do not include things done during the meeting.\n",
        "The tasks has to be clearly reported as finished by the speaker. Do not mention future plans.\n",
        "Only give one list of completed tasks for each speaker without any extra information.\"\"\"\n",
        "\n",
        "prompt_others_completed_tasks = \"\"\"Previous lists of completed tasks:\n",
        "{response}\n",
        "Amend the lists of completed tasks based on this part of the transcript:\n",
        "{chunk_text}\n",
        "Provide the lists of completed tasks as a whole, preserving all information from Previous lists of completed tasks.\n",
        "Only give one list of completed tasks for each speaker without any extra information.\"\"\"\n",
        "\n",
        "prompt_final_completed_tasks = \"\"\"Here is a list of completed tasks for each speaker:\n",
        "{gpt_responses}\n",
        "Format the list to use correct numbering and get rid of duplicate items.\"\"\"\n",
        "\n",
        "prompt_first_decisions = \"\"\"Meeting transcript:\n",
        "{chunk_text}\n",
        "Write the list of most important decisions made during the meeting.\n",
        "Keep it as short as possible.\n",
        "Only include decisions about the project, product or the working process without any extra information.\"\"\"\n",
        "\n",
        "prompt_others_decisions = \"\"\"Previous important decisions:\n",
        "{response}\n",
        "Amend the lists of most important decisions based on this part of the transcript:\n",
        "{chunk_text}\n",
        "Provide the list of most important decisions made during the meeting as a whole.\n",
        "Keep it as short as possible. You must start with all information from Previous important decisions.\n",
        "Only give the list of most important decisions without any extra information.\"\"\"\n",
        "\n",
        "prompt_final_decisions = \"\"\"Here is a list of key decisions made during a work meeting:\n",
        "{gpt_responses}\n",
        "Format the list to use correct numbering. Delete unimportant items that include general statements and not decisions.\n",
        "If several items can be merged into one, merge and abridge. Make the list as short as possible.\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NL-6FaX6uj6"
      },
      "source": [
        "## Getting summaries & tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEIGBgg_D_Ou"
      },
      "source": [
        "NB: I'm using gpt-4 by default. It's quite expensive. If you want to switch to gpt-3.5-turbo, you can do it in `process_meeting_teams` by specifying `openai_model='gpt-3.5-turbo'`. Note that on the last step (concatenate & abridge) we always use `gpt-4` as `gpt-3.5-turbo` performs poorly there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-3W1egLeIeDwT7SxYXXa2g48NwRBbTOc\n",
            "To: /Users/veronicasmilga/Desktop/Sentius/dream/prototypes/data/daily_sync_eng.docx\n",
            "100%|██████████| 27.3k/27.3k [00:04<00:00, 5.68kB/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'./data/daily_sync_eng.docx'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "url = 'https://drive.google.com/uc?id=1-3W1egLeIeDwT7SxYXXa2g48NwRBbTOc'\n",
        "filepath = './data/daily_sync_eng.docx'\n",
        "gdown.download(url, filepath, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "openai.api_key = \"YOUR OPENAI KEY HERE\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e1a0e3de087480487bf0eeae8eb9d73",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tokens in response: 112\n",
            "tokens in response: 202\n",
            "tokens in response: 102\n",
            "tokens in response: 215\n",
            "Processing responses to get the final answer. This should take around 45 seconds.\n",
            "At the series of meetings, the team discussed various technical and administrative issues alongside project updates. Technical issues discussed included audio quality, camera settings, issues with transcript formats, the usage of GPT-3/4/5 for better results, and the challenge with IP redirection. Solutions proposed for these challenges included optimizing task tracking, improving system authentication, and fine-tuning AI models, deemed more cost-effective.\n",
            "\n",
            "The need for better task status tracking was brought up by Ksenia, while Nika fixed the difficulties with transcript formats. Daniel suggested providing an API key and considered the utility of AI models - GPT-4 for training data and fine-tuning GPT-3/5 to cut costs. Artem worked on setting up the front-end container on the AWS machine and resolved package issues while Maxim fixed an issue with IP redirection.\n",
            "\n",
            "In administrative matters, some of the suggestions focused on improving productivity and organization. These included recording tasks for future reference, creating clarity within the team on task management, reviewing educational materials on product management, adding personality to automated tools and incorporating dialogue management generation parameters. Irina displayed an interest in customer development interviews while Daniel highlighted the importance of communication and trust. \n",
            "\n",
            "The team also discussed managerial roles and the unique approaches necessary for individual contributors and higher-level personnel. Marina brought up a suggestion about implementing new skills and Diliara confirmed that access to a machine had been given. In addition, a research meeting with Mike and a customer development interview with the Director Program Management at Meta were scheduled.\n",
            "\n",
            "The series of meetings concluded with progress made on tasks such as the back-end side of the skill and response selector task, and front-end container setup. However, further discussions were offered as the team looks forward to merging the front-end and back-end parts of the skill and response selectors and addressing issues with system sign-in.\n"
          ]
        }
      ],
      "source": [
        "# gpt-3.5-turbo summary (gpt-4 for concatenation and abridging)\n",
        "summary = process_meeting_teams(filepath, prompt_first_summary, prompt_final_summary, openai_model='gpt-3.5-turbo')\n",
        "print(summary[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7cdde9c034414a02a2308a2bff42dace",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tokens in response: 166\n",
            "tokens in response: 202\n",
            "tokens in response: 389\n",
            "tokens in response: 199\n",
            "Processing responses to get the final answer. This should take around 45 seconds.\n",
            "During the meeting, a variety of work-related topics were discussed by the participants. The talks revolved around task progression and optimising current operations. Ksenia outlined her work on enhancing the functionality of the system by working on task completion checks and conditions. She was also working on adding notes for clarification and fixing prompts. A pressing question during the meeting was raised by Marina about integrating browsing capabilities with Dream Builder, and Diliara offered her inputs explaining about an API available for parsing and performing actions on websites using JS snippets.\n",
            "\n",
            "The meeting further ventured into the complexities of processing transcripts in different formats, which has been a challenge for Nika. She also highlighted problems concerning chat GPT focusing primarily on the last part of the transcript, and a lack of efficient task status tracking. The solution of generating notes with GPT 4 was proposed, but the cost was a concern. Daniel pointed towards GPT 3 for debugging, and also suggested offering a corporate API key or financial reimbursement. Possible utilization of smaller, more specific models for cost-effectiveness was also suggested.\n",
            "\n",
            "A topic discussed by Diliara and Daniel was regarding a ‘basement’ they had talked about previously, but Daniel wasn’t able to provide the link. Daniel informed that he procured this information from discussions with people from Webex and Microsoft. The team also discussed the growing concerns about the deteriorating quality of GPT 4, especially since June. Mike recommended using corporate systems in the meantime, while improvements on the open-source model continue to be made. Some ancillary issues like problems with microphones and the importance of recording crucial information in written form were also discussed.\n",
            "\n",
            "Irina updated the team on her progress on customer development interviews and seeding more light on the educational document about product management that she shared on the team's channel. Daniel's response to her queries involved explaining different approaches taken for individuals and higher-level personnel.\n",
            "\n",
            "A detailed dialogue on tasks with Daniel was held, in which a custdev with Braincorp's head of PM Today was discussed alongside the crucial steps of gathering requirements, creating engineering plans, and regular operations. The group exchanged insights on project management and the need for trust-based communication and collaboration between teams. Marina emphasized on making tools reliable and enjoyable to use, while Daniel warned against the risks of nagging teammates.\n",
            "\n",
            "The group also discussed updates on pending tasks, like having a call with Phil and Furher to discuss progress on a new machine, and inclusion of skill selector response selector. Maxim also informed the team about some persisting authentication problems.\n",
            "\n",
            "Finally, the team spoke about the redirection issue Maxim had been working upon along with IP address modification of a machine and providing access to one more. Artem discussed fixing package issues and setting up a front-end container on an AWS machine. However, an authorization issue still needed to be addressed. They decided that the merge of Artem's and Maxim's sectors would be possible once this problem is resolved. Timofey contributed about his conversation with Irina concerning generative skill configuration. The meeting culminated with scheduling research meetings about website technical difficulties and follow-up customer development interviews.\n"
          ]
        }
      ],
      "source": [
        "# gpt-3.5-turbo summary (gpt-4 for concatenation and abridging)\n",
        "summary = process_meeting_teams(filepath, prompt_first_summary, prompt_final_summary)\n",
        "print(summary[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3947e79b43f64e5782744bd910e4e066",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tokens in response: 408\n",
            "tokens in response: 375\n",
            "Processing responses to get the final answer. This should take around 45 seconds.\n",
            "Meeting Summary:\n",
            "\n",
            "The meeting opened with Daniel tackling various technical issues. Ksenia gave updates on her task of adding clarification notes in response to user interaction, and voiced issues with ChatGPT. She suggested better means for debugging and browser agent integration.\n",
            "\n",
            "Financial concerns about high usage of GPT-4 were raised by Nika, who proposed using GPT-4 for channel note generation and GPT-3 for debugging as a cost-effective measure. Deployment of a corporate API key as a solution was suggested by Daniel. Nika additionally flagged plans of improving task status tracking.\n",
            "\n",
            "Irina shared updates on her tasks and a technical glitch she's been experiencing. Insights from her education classes about product management were also discussed. Mike then suggested use of GPT-3.5 for debugging and GPT-4 for sample generation, with longer-term plans of launching an open-source model for specific tasks.\n",
            "\n",
            "Daniel's focus was brought to the use of different GPT models during talks with different management levels. He emphasized the differing dialogue strategies required. Task updates concluded the meeting with a specific ask from Daniel to Dilara about task description modification.\n",
            "\n",
            "Additionally, the product management process was dissected, with Daniel breaking down the key stages. After a brief humorous miscommunication, the struggle of project managers in controlling information flow and dependency management was surfaced. Marina suggested a personality inclusion in automated tools to enhance their efficiency, referring to research from the chatbot realm.\n",
            "\n",
            "Task updates included Fedor's work on CI CD, Maxim's creation of a new machine and a skills selector response selector, Artem's progress on building a front-end container on AWS, and Timofey's discussion about generative skill configuration in a call with Irina and Dilara.\n",
            "\n",
            "Daniel highlighted crucial issues of a slowing front-end and ongoing authorization issues, marking them as immediate tasks. Noting a few upcoming customer development interviews, he underscored the necessity to sync on research with Mike. Daniel concluded the meeting with a reminder that resolving the authorization issue is a top priority.\n",
            "\n",
            "In conclusion, the meeting efficiently addressed a multitude of topics ranging from task updates, resource allocation, project management challenges, automation tool enhancements, and immediate priorities.\n"
          ]
        }
      ],
      "source": [
        "# gpt-4 summary\n",
        "summary = process_meeting_teams(filepath, prompt_first_summary, prompt_final_summary)\n",
        "print(summary[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e289d49e8ef447e8a083c4d86b9e9b66",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tokens in response: 159\n",
            "tokens in response: 220\n",
            "Processing responses to get the final answer. This should take around 45 seconds.\n",
            "Here is the list, renumbered and with duplicates removed: \n",
            "\n",
            "**Diliara Zharikova:**\n",
            "1. Correct the tasks in GitHub according to the meeting discussion.\n",
            "2. Review the skill selector and response selector elements of the interface.\n",
            "3. Meet with the research team to discuss future tasks.\n",
            "\n",
            "**Nika Smilga:**\n",
            "1. Implement better task status tracking for the transcription model.\n",
            "2. Add a prompt for each participant for task tracking and task detection.\n",
            "\n",
            "**Irina Nikitenko:**\n",
            "1. Summarize the customer development (custdev) interviews.\n",
            "2. Input summarized custdev interviews into a table.\n",
            "\n",
            "**Daniel Kornev:**\n",
            "1. Follow up on the customer development interviews.\n",
            "2. Provide access to Fedor for a submachine.\n",
            "3. Confirm John Morris' needs with Simon Muzio, the Director Program management at Meta.\n",
            "4. Call with a representative from an early-stage venture fund in Seattle.\n",
            "\n",
            "**Ksenia Petukhova:**\n",
            "1. Debug the completion of the task for adding notes for clarification.\n",
            "2. Start working on adding conditions to check which websites need to be used for the browsing agent.\n",
            "3. Create a new task for integrating Dream Builder with the browsing agent.\n",
            "\n",
            "**Fedor Ignatov:**\n",
            "1. Address the issue with the submachine, with Daniel's help.\n",
            "\n",
            "**Maxim Talimanchuk:**\n",
            "1. Solve the remaining issues related to authorization.\n",
            "\n",
            "**Artem Klementev:**\n",
            "1. Work with Maxim to fix the authorization problem, and then connect both Maxim's and his own portions of the skill selector and response selector tasks.\n",
            "\n",
            "**Timofey Syromyatnikoff:**\n",
            "1. Start and potentially complete the UI for generative skill configuration.\n",
            "   \n",
            "**The Development Team:**\n",
            "1. Prioritise fixing the authorization process to get their system up and running.\n",
            "\n",
            "**Mike:**\n",
            "1. Schedule a meeting to continue discussions on research topics.\n"
          ]
        }
      ],
      "source": [
        "current_tasks = process_meeting_teams(filepath, prompt_first_future_tasks, prompt_final_future_tasks)\n",
        "print(current_tasks[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d55f19a8e63c467d93ed713f2c95dcd0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tokens in response: 166\n",
            "tokens in response: 140\n",
            "Processing responses to get the final answer. This should take around 45 seconds.\n",
            "1. Diliara Zharikova: \n",
            "   - Modified tasks on Asana.\n",
            "   - Discussed task prioritization and allocation with the team.\n",
            "   - Conducted customer development interviews.\n",
            "\n",
            "2. Ksenia Petukhova: \n",
            "   - Worked on adding notes for clarification to enhance user interactions.\n",
            "   - Started working on updating task completion status by integrating the dream with the browser agent.\n",
            "\n",
            "3. Nika Smilga: \n",
            "   - Updated code to process different transcript formats from Teams.\n",
            "   - Corrected issues related to missing information from the beginning of meeting transcripts.\n",
            "\n",
            "4. Irina Nikitenko: \n",
            "   - Shared learning materials about product management roles.\n",
            "   - Read and summarized customer development interviews. \n",
            "\n",
            "5. Daniel Kornev: \n",
            "   - Conducted a customer development interview with John Moore, Head of Project Management.\n",
            "   - Worked on project planning.\n",
            "\n",
            "6. Maxim Talimanchuk:\n",
            "  - Built a new, more powerful machine.\n",
            "  - Integrated the Dream Builder.\n",
            "  - Added skill selector and response selector to the backend.\n",
            "\n",
            "7. Artem Klementev:\n",
            "  - Worked on creating the front end container on the AWS machine.\n",
            "  - Addressed some issues with the front end packages in the docker container.\n",
            "\n",
            "8. Timofey Syromyatnikoff:\n",
            "  - Participated in a call reviewing the design for the generative skill configuration.\n",
            "\n",
            "9. Fedor Ignatov:\n",
            "  - Participated in the call about AWS.\n",
            "\n",
            "10. Mike:\n",
            "  - Worked on consolidating research.\n"
          ]
        }
      ],
      "source": [
        "completed_tasks = process_meeting_teams(filepath, prompt_first_completed_tasks, prompt_final_completed_tasks)\n",
        "print(completed_tasks[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c8f73cf99364e32b23d831ac02b3da2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tokens in response: 214\n",
            "tokens in response: 205\n",
            "Processing responses to get the final answer. This should take around 45 seconds.\n",
            "1. The team will initially utilize Chat GPT for debugging and GPT-4 for generating samples, with future plans to fine-tune smaller models for specific tasks.\n",
            "2. Task status tracking will be refined to distinguish completed tasks from future ones, with assignments based on planning inputs from Nika and Diliara.\n",
            "3. To manage the cost of using API keys, a corporate credit card will be used in the short term, with a long-term cost optimization plan acknowledged.\n",
            "4. Responsibilities of product managers will be understood by reviewing the document shared by Irina.\n",
            "5. Recognizing the importance of customer interviews, Daniel outlined different strategies for talking to department heads versus individual contributors. Irina will sum up these interviews.\n",
            "6. The issue of authorization in the new front end was identified as a top priority to merge front and back end parts.\n",
            "7. A separate research meeting with Mike was recognized necessary to discuss project developments.\n",
            "8. A customer development interview with the Director Program management at Meta was planned to align John's needs with Simon's views. \n",
            "9. Backend's transition to a more powerful machine will necessitate a change in DNS records.\n",
            "10. Assistance will be provided to Fedor for accessing his machine.\n",
            "11. Diliara Zharikova and Daniel Kornev will collaborate with Marina and Irina on customer development by week's end.\n"
          ]
        }
      ],
      "source": [
        "decisions = process_meeting_teams(filepath, prompt_first_decisions, prompt_final_decisions, openai_model='gpt-4')\n",
        "print(decisions[-1])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "003e8b89c3874fc785b84974d76e0205": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e5d67e48dd94d43a4dec6d98c168556": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e71644cbc3cc46ed98b7583b829d67b8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1537d9df31ae4e2cb41bb9914bc15ac0",
            "value": 1
          }
        },
        "1537d9df31ae4e2cb41bb9914bc15ac0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "16e644485ffc4492a1aac068150af0fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2823ff1a3fed4b5c874002def883e613": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a0916992aa84176bbdf1230dcab6219": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c68c6d4a47ce4c24820c5b9d3936d3bf",
              "IPY_MODEL_a544d20da7554e6f9ae32a8ecbfa9240",
              "IPY_MODEL_b114ceabd92a4f9aaee69de89d8fb102"
            ],
            "layout": "IPY_MODEL_fd59e23d294640bcb0c63b75a729ef41"
          }
        },
        "44520f0660ae41d1b420d137bfb87e65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46df6cd751db45ba9d16d9ab5e400774": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cae1505a209454497ee28fc39a41c14",
            "placeholder": "​",
            "style": "IPY_MODEL_44520f0660ae41d1b420d137bfb87e65",
            "value": " 2/? [00:22&lt;00:00, 10.32s/it]"
          }
        },
        "5850dc0f649b4966b6d5deb441082d85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6784ccb56df84e95828ba19cd301254b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7389dc52403e4d8aae6e40af59c2a11d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf84c2379d514d43932e3e513e00b521",
            "placeholder": "​",
            "style": "IPY_MODEL_5850dc0f649b4966b6d5deb441082d85",
            "value": ""
          }
        },
        "7f711d0813c246b4a5849b9106b0bab7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acaa5cd694b74262984f85a44cae35f0",
            "placeholder": "​",
            "style": "IPY_MODEL_2823ff1a3fed4b5c874002def883e613",
            "value": ""
          }
        },
        "8cae1505a209454497ee28fc39a41c14": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99307bf3eb3e4e2783666d48daa4f86e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f711d0813c246b4a5849b9106b0bab7",
              "IPY_MODEL_aba59fc7fab64a97987cb579fbfc8f02",
              "IPY_MODEL_9da438d964814657a56138da423da965"
            ],
            "layout": "IPY_MODEL_c16f138cd0f24f5d944a2420fee5dce8"
          }
        },
        "9da438d964814657a56138da423da965": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef09d38585744f38b239f060e50ec2c8",
            "placeholder": "​",
            "style": "IPY_MODEL_e070226da80c425b8ad22c8415adc943",
            "value": " 2/? [00:52&lt;00:00, 25.45s/it]"
          }
        },
        "a04c5cd7e54c433fa2b526e07062de56": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2aa5c27a5cd484e9412a41382e9886a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7389dc52403e4d8aae6e40af59c2a11d",
              "IPY_MODEL_0e5d67e48dd94d43a4dec6d98c168556",
              "IPY_MODEL_46df6cd751db45ba9d16d9ab5e400774"
            ],
            "layout": "IPY_MODEL_d1cfff5e03bb40aa9df372ca84cf1db3"
          }
        },
        "a544d20da7554e6f9ae32a8ecbfa9240": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b96ed88881a9418fbc5cb41ae1e38bf8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c63e9ca376b84e0e80ff4c3af25906e5",
            "value": 1
          }
        },
        "aa0ea65d5d0f4ecda52941b136313fbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aba59fc7fab64a97987cb579fbfc8f02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e884e8c12ee6475aa6010ff91f95034b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_003e8b89c3874fc785b84974d76e0205",
            "value": 1
          }
        },
        "acaa5cd694b74262984f85a44cae35f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b114ceabd92a4f9aaee69de89d8fb102": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a04c5cd7e54c433fa2b526e07062de56",
            "placeholder": "​",
            "style": "IPY_MODEL_16e644485ffc4492a1aac068150af0fd",
            "value": " 2/? [01:08&lt;00:00, 35.11s/it]"
          }
        },
        "b96ed88881a9418fbc5cb41ae1e38bf8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "bf84c2379d514d43932e3e513e00b521": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c16f138cd0f24f5d944a2420fee5dce8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c63e9ca376b84e0e80ff4c3af25906e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c68c6d4a47ce4c24820c5b9d3936d3bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6784ccb56df84e95828ba19cd301254b",
            "placeholder": "​",
            "style": "IPY_MODEL_aa0ea65d5d0f4ecda52941b136313fbc",
            "value": ""
          }
        },
        "d1cfff5e03bb40aa9df372ca84cf1db3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e070226da80c425b8ad22c8415adc943": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e71644cbc3cc46ed98b7583b829d67b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e884e8c12ee6475aa6010ff91f95034b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ef09d38585744f38b239f060e50ec2c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd59e23d294640bcb0c63b75a729ef41": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
