services:
  agent:
    command: sh -c 'bin/wait && python -m deeppavlov_agent.run agent.pipeline_config=assistant_dists/management_assistant/pipeline_conf.json agent.channel=$AGENT_CHANNEL'
    environment:
      WAIT_HOSTS: "llm-based-response-selector-gpt4:8003, combined-classification:8087, sentence-ranker:8128, 
        prompt-selector:8135, openai-api-chatgpt:8145, dff-general-pm-prompted-skill:8189, dff-meeting-analysis-skill:8186, 
        doc-processor-from-atts:8188, llm-based-skill-selector:8182,
        openai-api-gpt4:8159, teams-postprocessor:8019"
      WAIT_HOSTS_TIMEOUT: ${WAIT_TIMEOUT:-1000}
      HIGH_PRIORITY_INTENTS: 1
      RESTRICTION_FOR_SENSITIVE_CASE: 1
      ALWAYS_TURN_ON_ALL_SKILLS: 0
      LANGUAGE: EN
      FALLBACK_FILE: fallbacks_sentius_en.json
      FALLBACK_TO_DOCS_FILE: fallbacks_sentius_en_docs.json
      HELP_FILE: help_en.json
      START_DIALOG_FILE: start_dialog_en.json

  files:
    image: julienmeerschart/simple-file-upload-download-server

  teams-postprocessor:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8019
        SERVICE_NAME: teams_postprocessor
      context: .
      dockerfile: ./annotators/teams_postprocessor/Dockerfile
    command: flask run -h 0.0.0.0 -p 8019
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 100M
        reservations:
          memory: 100M

  llm-based-skill-selector:
    env_file: [ .env, .env_secret_azure ]
    build:
      args:
        SERVICE_PORT: 8182
        SERVICE_NAME: skill_selector
        GENERATIVE_SERVICE_URL: http://openai-api-chatgpt:8145/respond
        GENERATIVE_SERVICE_CONFIG: openai-chatgpt-short.json
        GENERATIVE_TIMEOUT: 10
        N_UTTERANCES_CONTEXT: 3
        N_TURNS_TO_KEEP_DOC: 5
        PROMPT_FILE: common/prompts/skill_selector.json
      context: .
      dockerfile: ./skill_selectors/llm_based_skill_selector/Dockerfile
    command: flask run -h 0.0.0.0 -p 8182
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 100M
        reservations:
          memory: 100M

  doc-processor-from-atts:
    env_file: [ .env ]
    build:
      context: .
      dockerfile: ./annotators/doc_processor/Dockerfile
      args:
        SERVICE_PORT: 8188
        SERVICE_NAME: doc_processor
        FILE_SERVER_TIMEOUT: 30.0
        N_TURNS_TO_KEEP_DOC: 5
    command: python -m flask run -h 0.0.0.0 -p 8188
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 500M
        reservations:
          memory: 500M

  combined-classification:
    env_file: [ .env ]
    build:
      args:
        CONFIG: combined_classifier.json
        SERVICE_PORT: 8087
      context: .
      dockerfile: ./annotators/combined_classification/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8087 --timeout 600
    environment:
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 2G

  llm-based-response-selector-gpt4:
    env_file: [ .env, .env_secret_azure ]
    build:
      args:
        SERVICE_PORT: 8003
        SERVICE_NAME: response_selector
        LANGUAGE: EN
        GENERATIVE_SERVICE_URL: http://openai-api-gpt4:8159/respond
        GENERATIVE_SERVICE_CONFIG: openai-chatgpt-short.json
        GENERATIVE_TIMEOUT: 120
        N_UTTERANCES_CONTEXT: 1
        CHOOSE_HYP_BY_NUM: 1
        FILTER_TOXIC_OR_BADLISTED: 0
        PROMPT_FILE: common/prompts/response_selector_by_number.json
      context: .
      dockerfile: ./response_selectors/llm_based_response_selector/Dockerfile
    command: flask run -h 0.0.0.0 -p 8003
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 100M
        reservations:
          memory: 100M

  prompt-selector:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8135
        SERVICE_NAME: prompt_selector
        SENTENCE_RANKER_SERVICE_URL: http://sentence-ranker:8128/respond
        N_SENTENCES_TO_RETURN: 3
      context: .
      dockerfile: ./annotators/prompt_selector/Dockerfile
    command: flask run -h 0.0.0.0 -p 8135
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 100M
        reservations:
          memory: 100M

  sentence-ranker:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8128
        SERVICE_NAME: sentence_ranker
        PRETRAINED_MODEL_NAME_OR_PATH: sentence-transformers/all-MiniLM-L6-v2
      context: ./services/sentence_ranker/
    command: flask run -h 0.0.0.0 -p 8128
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 3G
        reservations:
          memory: 3G

  openai-api-chatgpt:
    env_file: [ .env, .env_azure ]
    build:
      args:
        SERVICE_PORT: 8145
        SERVICE_NAME: openai_api_chatgpt
        PRETRAINED_MODEL_NAME_OR_PATH: gpt-3.5-turbo
      context: .
      dockerfile: ./services/openai_api_lm/Dockerfile
    command: flask run -h 0.0.0.0 -p 8145
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 500M
        reservations:
          memory: 100M

  openai-api-gpt4:
    env_file: [ .env, .env_azure ]
    build:
      args:
        SERVICE_PORT: 8159
        SERVICE_NAME: openai_api_gpt4
        PRETRAINED_MODEL_NAME_OR_PATH: gpt-4
      context: .
      dockerfile: ./services/openai_api_lm/Dockerfile
    command: flask run -h 0.0.0.0 -p 8159
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 500M
        reservations:
          memory: 100M

  dff-general-pm-prompted-skill:
    env_file: [ .env, .env_secret_azure ]
    build:
      args:
        SERVICE_PORT: 8189
        SERVICE_NAME: dff_general_pm_prompted_skill
        PROMPT_FILE: common/prompts/general_pm.json
        GENERATIVE_SERVICE_URL: http://openai-api-chatgpt:8145/respond
        GENERATIVE_SERVICE_CONFIG: openai-chatgpt-long.json
        GENERATIVE_TIMEOUT: 120
        N_UTTERANCES_CONTEXT: 7
      context: .
      dockerfile: ./skills/dff_template_prompted_skill/Dockerfile
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  dff-meeting-analysis-skill:
    env_file: [ .env, .env_secret_azure ]
    build:
      args:
        SERVICE_PORT: 8186
        SERVICE_NAME: dff_meeting_analysis_skill
        GENERATIVE_SERVICE_URL: http://openai-api-gpt4:8159/respond
        GENERATIVE_SERVICE_CONFIG: openai-gpt4-long.json
        GENERATIVE_TIMEOUT: 120
        SHORT_GENERATIVE_SERVICE_URL: http://openai-api-chatgpt:8145/respond
        SHORT_GENERATIVE_SERVICE_CONFIG: openai-chatgpt-long.json
        SHORT_GENERATIVE_TIMEOUT: 30
        N_UTTERANCES_CONTEXT: 7
        FILE_SERVER_TIMEOUT: 30.0
        TRANSCRIPTOR_SERVICE_URL: 'http://3.86.192.202:8171'
      context: .
      dockerfile: ./skills/dff_meeting_analysis_skill/Dockerfile
    deploy:
      resources:
        limits:
          memory: 500M
        reservations:
          memory: 500M

  dff-google-api-skill:
    env_file: [ .env,.env_secret ]
    build:
      args:
        SERVICE_PORT: 8162
        SERVICE_NAME: dff_google_api_skill
      context: .
      dockerfile: ./skills/dff_google_api_skill/Dockerfile
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

version: '3.7'
