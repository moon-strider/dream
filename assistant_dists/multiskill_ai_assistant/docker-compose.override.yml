services:
  agent:
    command: sh -c 'bin/wait && python -m deeppavlov_agent.run agent.pipeline_config=assistant_dists/multiskill_ai_assistant/pipeline_conf.json'
    environment:
      WAIT_HOSTS: "sentseg:8011, llm-based-response-selector:8003, combined-classification:8087,
        sentence-ranker:8128, prompt-selector:8135, 
        openai-api-davinci3:8131, dff-dream-persona-davinci3-prompted-skill:8137,
        dff-casual-email-prompted-skill:8154, dff-meeting-notes-prompted-skill:8155,
        dff-official-email-prompted-skill:8156, dff-plan-for-article-prompted-skill:8157"
      WAIT_HOSTS_TIMEOUT: ${WAIT_TIMEOUT:-1000}
      HIGH_PRIORITY_INTENTS: 1
      RESTRICTION_FOR_SENSITIVE_CASE: 1
      ALWAYS_TURN_ON_ALL_SKILLS: 0
      LANGUAGE: EN

  sentseg:
    env_file: [ .env ]
    build:
      context: ./annotators/SentSeg/
    command: flask run -h 0.0.0.0 -p 8011
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 1.5G
        reservations:
          memory: 1.5G

  combined-classification:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8087
        SERVICE_NAME: combined_classification
        CONFIG: combined_classifier.json
      context: .
      dockerfile: ./annotators/combined_classification/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8087 --timeout 600
    environment:
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 2G

  llm-based-response-selector:
    env_file: [ .env,.env_secret ]
    build:
      args:
        SERVICE_PORT: 8003
        SERVICE_NAME: response_selector
        LANGUAGE: EN
        GENERATIVE_SERVICE_URL: http://openai-api-davinci3:8131/respond
        GENERATIVE_SERVICE_CONFIG: openai-text-davinci-003-long.json
        GENERATIVE_TIMEOUT: 120
        N_UTTERANCES_CONTEXT: 7
        ENVVARS_TO_SEND: OPENAI_API_KEY,OPENAI_ORGANIZATION
        FILTER_TOXIC_OR_BADLISTED: 1
      context: .
      dockerfile: ./response_selectors/llm_based_response_selector/Dockerfile
    command: flask run -h 0.0.0.0 -p 8003
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 100M
        reservations:
          memory: 100M

  prompt-selector:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8135
        SERVICE_NAME: prompt_selector
        N_SENTENCES_TO_RETURN: 2
        PROMPTS_TO_CONSIDER: dream_persona,casual_email,meeting_notes,official_email,plan_for_article
      context: .
      dockerfile: ./annotators/prompt_selector/Dockerfile
    command: flask run -h 0.0.0.0 -p 8135
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 100M
        reservations:
          memory: 100M

  sentence-ranker:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8128
        SERVICE_NAME: sentence_ranker
        PRETRAINED_MODEL_NAME_OR_PATH: sentence-transformers/all-MiniLM-L6-v2
      context: ./services/sentence_ranker/
    command: flask run -h 0.0.0.0 -p 8128
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 3G
        reservations:
          memory: 3G

  openai-api-davinci3:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8131
        SERVICE_NAME: openai_api_davinci3
        PRETRAINED_MODEL_NAME_OR_PATH: text-davinci-003
      context: .
      dockerfile: ./services/openai_api_lm/Dockerfile
    command: flask run -h 0.0.0.0 -p 8131
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 100M
        reservations:
          memory: 100M

  dff-dream-persona-davinci3-prompted-skill:
    env_file: [ .env,.env_secret ]
    build:
      args:
        SERVICE_PORT: 8137
        SERVICE_NAME: dff_dream_persona_prompted_skill
        PROMPT_FILE: common/prompts/dream_persona.json
        GENERATIVE_SERVICE_URL: http://openai-api-davinci3:8131/respond
        GENERATIVE_SERVICE_CONFIG: openai-text-davinci-003-long.json
        GENERATIVE_TIMEOUT: 120
        N_UTTERANCES_CONTEXT: 7
        ENVVARS_TO_SEND: OPENAI_API_KEY,OPENAI_ORGANIZATION
      context: .
      dockerfile: ./skills/dff_template_prompted_skill/Dockerfile
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  dff-casual-email-prompted-skill:
    env_file: [ .env,.env_secret ]
    build:
      args:
        SERVICE_PORT: 8154
        SERVICE_NAME: dff_casual_email_prompted_skill
        PROMPT_FILE: common/prompts/casual_email.json
        GENERATIVE_SERVICE_URL: http://openai-api-davinci3:8131/respond
        GENERATIVE_SERVICE_CONFIG: openai-text-davinci-003-long.json
        GENERATIVE_TIMEOUT: 120
        N_UTTERANCES_CONTEXT: 7
        ENVVARS_TO_SEND: OPENAI_API_KEY,OPENAI_ORGANIZATION
      context: .
      dockerfile: ./skills/dff_template_prompted_skill/Dockerfile
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  dff-meeting-notes-prompted-skill:
    env_file: [ .env,.env_secret ]
    build:
      args:
        SERVICE_PORT: 8155
        SERVICE_NAME: dff_meeting_notes_prompted_skill
        PROMPT_FILE: common/prompts/meeting_notes.json
        GENERATIVE_SERVICE_URL: http://openai-api-davinci3:8131/respond
        GENERATIVE_SERVICE_CONFIG: openai-text-davinci-003-long.json
        GENERATIVE_TIMEOUT: 120
        N_UTTERANCES_CONTEXT: 7
        ENVVARS_TO_SEND: OPENAI_API_KEY,OPENAI_ORGANIZATION
      context: .
      dockerfile: ./skills/dff_template_prompted_skill/Dockerfile
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  dff-official-email-prompted-skill:
    env_file: [ .env,.env_secret ]
    build:
      args:
        SERVICE_PORT: 8156
        SERVICE_NAME: dff_official_email_prompted_skill
        PROMPT_FILE: common/prompts/official_email.json
        GENERATIVE_SERVICE_URL: http://openai-api-davinci3:8131/respond
        GENERATIVE_SERVICE_CONFIG: openai-text-davinci-003-long.json
        GENERATIVE_TIMEOUT: 120
        N_UTTERANCES_CONTEXT: 7
        ENVVARS_TO_SEND: OPENAI_API_KEY,OPENAI_ORGANIZATION
      context: .
      dockerfile: ./skills/dff_template_prompted_skill/Dockerfile
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  dff-plan-for-article-prompted-skill:
    env_file: [ .env,.env_secret ]
    build:
      args:
        SERVICE_PORT: 8157
        SERVICE_NAME: dff_plan_for_article_prompted_skill
        PROMPT_FILE: common/prompts/plan_for_article.json
        GENERATIVE_SERVICE_URL: http://openai-api-davinci3:8131/respond
        GENERATIVE_SERVICE_CONFIG: openai-text-davinci-003-long.json
        GENERATIVE_TIMEOUT: 120
        N_UTTERANCES_CONTEXT: 7
        ENVVARS_TO_SEND: OPENAI_API_KEY,OPENAI_ORGANIZATION
      context: .
      dockerfile: ./skills/dff_template_prompted_skill/Dockerfile
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

version: '3.7'
